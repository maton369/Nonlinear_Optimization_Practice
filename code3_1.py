"""
コード3.1 ■ 最急降下法（Steepest Descent Method）のコード
このプログラムは、非線形最適化の基本手法である「最急降下法」を実装している。
Wolfe条件に基づく線探索（line_Wolfe）を用いて、最適なステップ幅 α を求める。
"""

import numpy as np
from code2_2 import *  # Wolfe条件を用いた線探索アルゴリズム（コード2.2）をインポート


def SteepestDescent(obj_f, nab_f, x_k, max_iter=1000, eps=1.0e-8):
    """
    最急降下法（Steepest Descent法）による最適化を行う関数。

    Parameters
    ----------
    obj_f : function
        最小化したい目的関数 f(x)
    nab_f : function
        目的関数の勾配（∇f(x)）を返す関数
    x_k : ndarray
        初期点（探索開始点）
    max_iter : int, optional
        最大反復回数（デフォルト: 1000）
    eps : float, optional
        収束判定の閾値。勾配ノルムがこの値以下になると終了（デフォルト: 1e-8）

    Returns
    -------
    x_k : ndarray
        最適化後の推定解（局所最小点）
    """

    # 反復開始
    for k in range(max_iter):

        # ------------------------------------------------------------
        # (1) 探索方向の計算
        # 最急降下法では探索方向 d_k は「負の勾配方向」
        #   d_k = -∇f(x_k)
        # これが「最も急速に関数値を減少させる方向」である
        # ------------------------------------------------------------
        d_k = -nab_f(x_k)

        # ------------------------------------------------------------
        # (2) Wolfe条件に基づく線探索
        # line_Wolfe関数を用いて、適切なステップ幅 α を求める
        # ------------------------------------------------------------
        alpha = line_Wolfe(obj_f, nab_f, x_k, d_k)

        # ------------------------------------------------------------
        # (3) 次の探索点へ更新
        #   x_{k+1} = x_k + α * d_k
        # ------------------------------------------------------------
        x_k = x_k + alpha * d_k

        # ------------------------------------------------------------
        # (4) 収束判定
        # 勾配ノルムが閾値 eps 以下であれば最適解に到達したとみなす
        # ------------------------------------------------------------
        if np.linalg.norm(nab_f(x_k)) <= eps:
            break

    # ------------------------------------------------------------
    # (5) 結果の出力
    # 反復回数と最終的な目的関数値を表示
    # ------------------------------------------------------------
    print("SD, iter:", k + 1, "f(x):", obj_f(x_k))
    return x_k
