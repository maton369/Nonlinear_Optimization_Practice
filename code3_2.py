"""
コード3.3 ■ 非線形共役勾配法（Nonlinear Conjugate Gradient Method, Hestenes-Stiefel法）のコード
このプログラムは、非線形最適化における高速な勾配法「非線形共役勾配法」を実装している。
最急降下法の改良版であり、各ステップで前回の探索方向を考慮して効率的に最適化を行う。
Wolfe条件に基づく線探索（line_Wolfe）を使用してステップ幅 α を決定する。
"""

import numpy as np
from code2_2 import *  # Wolfe条件を用いた線探索アルゴリズム（コード2.2）をインポート


def CG_HS(obj_f, nab_f, x_k, max_iter=1000, eps=1.0e-8):
    """
    非線形共役勾配法（Hestenes-Stiefel法）による最適化を行う関数。

    Parameters
    ----------
    obj_f : function
        最小化したい目的関数 f(x)
    nab_f : function
        目的関数の勾配（∇f(x)）を返す関数
    x_k : ndarray
        初期点（探索の開始点）
    max_iter : int, optional
        最大反復回数（デフォルト: 1000）
    eps : float, optional
        収束判定の閾値。勾配ノルムがこの値以下になると終了（デフォルト: 1e-8）

    Returns
    -------
    x_k : ndarray
        最適化後の推定解（局所最小点）
    """

    # ------------------------------------------------------------
    # (1) 初期化
    # 初期点での勾配と探索方向を設定
    # d_k = -∇f(x_k)（最急降下方向）
    # ------------------------------------------------------------
    nab_f_k = nab_f(x_k)  # 現在の勾配 ∇f(x_k)
    d_k = -nab_f_k  # 初期探索方向（負の勾配方向）

    # ------------------------------------------------------------
    # (2) メインループ（最大 max_iter 回）
    # 各ステップで Wolfe条件を用いて最適なステップ幅を求め、
    # Hestenes-Stiefel（HS）公式で共役方向を更新する。
    # ------------------------------------------------------------
    for k in range(max_iter):

        # (2-1) Wolfe条件に基づく線探索でステップ幅 α を求める
        alpha = line_Wolfe(obj_f, nab_f, x_k, d_k)

        # (2-2) 探索点を更新：x_{k+1} = x_k + α * d_k
        x_k = x_k + alpha * d_k

        # (2-3) 前回の勾配を保存し、新しい勾配を計算
        nab_f_k_old = nab_f_k
        nab_f_k = nab_f(x_k)

        # (2-4) 勾配の大きさが十分小さければ収束と判定
        if np.linalg.norm(nab_f_k) <= eps:
            break

        # --------------------------------------------------------
        # (2-5) β の更新：Hestenes-Stiefel (HS) 公式
        #   β_HS = (∇f_k^T (∇f_k - ∇f_{k-1})) / (d_{k-1}^T (∇f_k - ∇f_{k-1}))
        # この β により、前回の探索方向と共役な新しい方向を決定。
        # --------------------------------------------------------
        beta = nab_f_k @ (nab_f_k - nab_f_k_old) / (d_k @ (nab_f_k - nab_f_k_old))

        # (2-6) 探索方向の更新
        d_k = -nab_f_k + beta * d_k

    # ------------------------------------------------------------
    # (3) 結果出力
    # 反復回数と最終的な目的関数値を表示
    # ------------------------------------------------------------
    print("CG(HS), iter:", k + 1, "f(x):", obj_f(x_k))
    return x_k
