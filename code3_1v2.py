"""
コード3.1 ■ 最急降下法（Steepest Descent法：点列ログ付き）
このプログラムは最急降下法を用いた非線形最適化を行い、
各反復ステップで得られた点（x_k）をすべて記録する。
探索方向は負の勾配方向を用い、ステップ幅はWolfe条件に基づく線探索により決定する。
"""

import numpy as np
from code2_2 import *  # Wolfe条件を用いた線探索アルゴリズム（コード2.2）をインポート


def SteepestDescent(obj_f, nab_f, x_k, max_iter=1000, eps=1.0e-8):
    """
    最急降下法（Steepest Descent法）による最適化を行い、点列ログを出力する関数。

    Parameters
    ----------
    obj_f : function
        最小化したい目的関数 f(x)
    nab_f : function
        目的関数の勾配（∇f(x)）を返す関数
    x_k : ndarray
        初期点（探索の開始点）
    max_iter : int, optional
        最大反復回数（デフォルト: 1000）
    eps : float, optional
        収束判定の閾値。勾配ノルムがこの値以下になると終了（デフォルト: 1e-8）

    Returns
    -------
    seq_x : ndarray
        各反復ステップでの点 x_k を順に格納した配列
    """

    # ------------------------------------------------------------
    # (1) 点列ログを格納するリストを初期化
    # 初期点 x_k をまずリストに追加しておく
    # ------------------------------------------------------------
    seq_x = [x_k]

    # ------------------------------------------------------------
    # (2) 反復処理（最大 max_iter 回）
    # 各ステップで：
    #   - 探索方向の決定
    #   - Wolfe条件による線探索
    #   - 点の更新とログ記録
    #   - 収束判定
    # ------------------------------------------------------------
    for k in range(max_iter):

        # 探索方向を計算（最急降下法では負の勾配方向）
        d_k = -nab_f(x_k)

        # Wolfe条件を満たすステップ幅 α を線探索で決定
        alpha = line_Wolfe(obj_f, nab_f, x_k, d_k)

        # 次の点に更新：x_{k+1} = x_k + α * d_k
        x_k = x_k + alpha * d_k

        # 新しい点をログに追加
        seq_x.append(x_k)

        # 勾配ノルムが十分に小さくなったら終了
        if np.linalg.norm(nab_f(x_k)) <= eps:
            break

    # ------------------------------------------------------------
    # (3) 結果出力
    # 反復回数と最終目的関数値を表示
    # ------------------------------------------------------------
    print("SD, iter:", k + 1, "f(x):", obj_f(x_k))

    # ------------------------------------------------------------
    # (4) 点列ログを NumPy 配列に変換して返す
    # 各行が1ステップの点ベクトルを表す
    # ------------------------------------------------------------
    return np.array(seq_x)
